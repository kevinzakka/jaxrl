# nanorl

A tiny reinforcement learning codebase for continuous control, built on top of [JAX](https://github.com/google/jax). Minimal, self-contained and research-friendly. Inspired by Ilya Kostrikov's [jaxrl](https://github.com/ikostrikov/jaxrl).

## Installation

1. `pip install --upgrade "jax[cuda]" -f https://storage.googleapis.com/jax-releases/jax_cuda_releases.html`
2. `git clone https://github.com/kevinzakka/nanorl` && `cd nanorl`
3. `pip install -e .`
